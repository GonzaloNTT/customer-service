2025-10-09 00:02:03 [AsyncResolver-bootstrap-executor-%d] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
2025-10-09 00:02:50 [parallel-1] DEBUG c.b.c.i.e.ClienteNaturalController - POST /cliente/natural
2025-10-09 00:02:50 [reactor-http-nio-3] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Registrando cliente natural: ClienteNaturalCommand[id=null, usuario=DatosUsuario[documento=DocumentoIdentificacion[type=DNI, numero=00000002], telefono=Telefono[numero=+51999999999, imei=7456745674567], correo=Correo[value=juan.perez@example.com]], tipo=NORMAL]
2025-10-09 00:02:50 [reactor-http-nio-3] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Obteniendo cliente natural por Docuemtno: DNI 00000002
2025-10-09 00:02:53 [nioEventLoopGroup-3-18] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural registrado exitosamente: 887c376e-63f2-4c91-9811-f566f597c36f
2025-10-09 00:03:09 [parallel-2] DEBUG c.b.c.i.e.ClienteNaturalController - PUT /cliente/natural/887c376e-63f2-4c91-9811-f566f597c36f
2025-10-09 00:03:09 [reactor-http-nio-3] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Actualizando cliente natural con ID: 887c376e-63f2-4c91-9811-f566f597c36f
2025-10-09 00:03:10 [nioEventLoopGroup-3-18] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural actualizado exitosamente: 887c376e-63f2-4c91-9811-f566f597c36f
2025-10-09 00:06:18 [parallel-3] DEBUG c.b.c.i.e.ClienteNaturalController - POST /cliente/natural
2025-10-09 00:06:18 [reactor-http-nio-5] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Registrando cliente natural: ClienteNaturalCommand[id=null, usuario=DatosUsuario[documento=DocumentoIdentificacion[type=DNI, numero=00000003], telefono=Telefono[numero=+51999999999, imei=7456745674567], correo=Correo[value=juan.perez@example.com]], tipo=NORMAL]
2025-10-09 00:06:18 [reactor-http-nio-5] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Obteniendo cliente natural por Docuemtno: DNI 00000003
2025-10-09 00:06:19 [nioEventLoopGroup-3-18] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural registrado exitosamente: 8c50505d-de95-44cd-84e6-d5ff071f595f
2025-10-09 00:06:28 [parallel-4] DEBUG c.b.c.i.e.ClienteNaturalController - PUT /cliente/natural/8c50505d-de95-44cd-84e6-d5ff071f595f
2025-10-09 00:06:28 [reactor-http-nio-5] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Actualizando cliente natural con ID: 8c50505d-de95-44cd-84e6-d5ff071f595f
2025-10-09 00:06:28 [nioEventLoopGroup-3-18] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural actualizado exitosamente: 8c50505d-de95-44cd-84e6-d5ff071f595f
2025-10-09 00:07:03 [AsyncResolver-bootstrap-executor-%d] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
2025-10-09 00:30:12 [background-preinit] INFO  o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.3.Final
2025-10-09 00:30:12 [main] INFO  c.b.c.CustomerServiceApplication - Starting CustomerServiceApplication using Java 21.0.8 with PID 15832 (D:\NTT DATA\customer-service\target\classes started by Gonzalo in D:\NTT DATA\customer-service)
2025-10-09 00:30:12 [main] DEBUG c.b.c.CustomerServiceApplication - Running with Spring Boot v3.4.10, Spring v6.2.11
2025-10-09 00:30:12 [main] INFO  c.b.c.CustomerServiceApplication - No active profile set, falling back to 1 default profile: "default"
2025-10-09 00:30:14 [main] INFO  org.mongodb.driver.client - MongoClient with metadata {"application": {"name": "Cluster0"}, "driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "5.2.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/21.0.8+9-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='xaleons72_db_user', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@5d3f8661, socketChannelClass=null, allocator=null, sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@1df9f7c6], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4b5aa48b, com.mongodb.Jep395RecordCodecProvider@51c008fd, com.mongodb.KotlinCodecProvider@70ed902a]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=cluster0.bst1l3t.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-mp34t7-shard-0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@22f80e36], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='Cluster0', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
2025-10-09 00:30:15 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:15 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:15 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:16 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=534122800, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e520a3031463f16b1ec4de, counter=6}, lastWriteDate=Thu Oct 09 00:30:16 COT 2025, lastUpdateTimeNanos=389435799114000}
2025-10-09 00:30:16 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=534121100, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e5710e940ac22a86255593, counter=4}, lastWriteDate=Thu Oct 09 00:30:16 COT 2025, lastUpdateTimeNanos=389435799114000}
2025-10-09 00:30:16 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, type=REPLICA_SET_PRIMARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=534122400, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000025a, setVersion=324, topologyVersion=TopologyVersion{processId=68e54c58ed1645ec4e11f896, counter=7}, lastWriteDate=Thu Oct 09 00:30:16 COT 2025, lastUpdateTimeNanos=389435799114100}
2025-10-09 00:30:16 [cluster-ClusterId{value='68e74866dfe27609d7fe8c07', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Discovered replica set primary ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 with max election id 7fffffff000000000000025a and max set version 324
2025-10-09 00:30:16 [main] WARN  o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2025-10-09 00:30:16 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = customer-service-admin-0
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-09 00:30:17 [main] INFO  o.a.k.c.admin.AdminClientConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759987817084
2025-10-09 00:30:17 [kafka-admin-client-thread | customer-service-admin-0] WARN  o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=customer-service-admin-0] The DescribeTopicPartitions API is not supported, using Metadata API to describe topics.
2025-10-09 00:30:17 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for customer-service-admin-0 unregistered
2025-10-09 00:30:17 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:30:17 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:30:17 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2025-10-09 00:30:17 [main] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
2025-10-09 00:30:17 [main] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1759987817643 with initial instances count: 2
2025-10-09 00:30:17 [main] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1759987817646, current=UP, previous=STARTING]
2025-10-09 00:30:17 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:0: registering service...
2025-10-09 00:30:17 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:0 - registration status: 204
2025-10-09 00:30:17 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customer-service-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customer-service-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-09 00:30:17 [main] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-10-09 00:30:17 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:30:17 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:30:17 [main] INFO  o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:30:17 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759987817781
2025-10-09 00:30:17 [main] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Subscribed to topic(s): customer-created
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Cluster ID: fr9HVN4fSCq5BrFxSZ-pAQ
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-10-09 00:30:17 [main] INFO  c.b.c.CustomerServiceApplication - Started CustomerServiceApplication in 8.435 seconds (process running for 8.992)
2025-10-09 00:30:17 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1759987817811, current=DOWN, previous=UP]
2025-10-09 00:30:17 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:0: registering service...
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] (Re-)joining group
2025-10-09 00:30:17 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:0 - registration status: 204
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: need to re-join with the given member-id: consumer-customer-service-group-1-a75b4653-0137-4137-adac-77cfb51530c5
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:30:17 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customer-service-group-1 unregistered
2025-10-09 00:30:25 [background-preinit] INFO  o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.3.Final
2025-10-09 00:30:25 [main] INFO  c.b.c.CustomerServiceApplication - Starting CustomerServiceApplication using Java 21.0.8 with PID 1348 (D:\NTT DATA\customer-service\target\classes started by Gonzalo in D:\NTT DATA\customer-service)
2025-10-09 00:30:25 [main] DEBUG c.b.c.CustomerServiceApplication - Running with Spring Boot v3.4.10, Spring v6.2.11
2025-10-09 00:30:25 [main] INFO  c.b.c.CustomerServiceApplication - No active profile set, falling back to 1 default profile: "default"
2025-10-09 00:30:28 [main] INFO  org.mongodb.driver.client - MongoClient with metadata {"application": {"name": "Cluster0"}, "driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "5.2.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/21.0.8+9-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='xaleons72_db_user', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@51c008fd, socketChannelClass=null, allocator=null, sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@70ed902a], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@22f80e36, com.mongodb.Jep395RecordCodecProvider@3c98981e, com.mongodb.KotlinCodecProvider@6dcee890]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=cluster0.bst1l3t.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-mp34t7-shard-0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@713e49c3], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='Cluster0', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
2025-10-09 00:30:28 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:28 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:28 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:30:29 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=755196600, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e520a3031463f16b1ec4de, counter=6}, lastWriteDate=Thu Oct 09 00:30:30 COT 2025, lastUpdateTimeNanos=389448900934400}
2025-10-09 00:30:29 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, type=REPLICA_SET_PRIMARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=738667800, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000025a, setVersion=324, topologyVersion=TopologyVersion{processId=68e54c58ed1645ec4e11f896, counter=7}, lastWriteDate=Thu Oct 09 00:30:30 COT 2025, lastUpdateTimeNanos=389448900934200}
2025-10-09 00:30:29 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=737913800, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e5710e940ac22a86255593, counter=4}, lastWriteDate=Thu Oct 09 00:30:30 COT 2025, lastUpdateTimeNanos=389448900940200}
2025-10-09 00:30:29 [cluster-ClusterId{value='68e748738413154339d845fc', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Discovered replica set primary ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 with max election id 7fffffff000000000000025a and max set version 324
2025-10-09 00:30:29 [main] WARN  o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2025-10-09 00:30:29 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = customer-service-admin-0
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-09 00:30:30 [main] INFO  o.a.k.c.admin.AdminClientConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759987830106
2025-10-09 00:30:30 [kafka-admin-client-thread | customer-service-admin-0] WARN  o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=customer-service-admin-0] The DescribeTopicPartitions API is not supported, using Metadata API to describe topics.
2025-10-09 00:30:30 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for customer-service-admin-0 unregistered
2025-10-09 00:30:30 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:30:30 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:30:30 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2025-10-09 00:30:30 [main] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
2025-10-09 00:30:30 [main] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1759987830576 with initial instances count: 3
2025-10-09 00:30:30 [main] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1759987830581, current=UP, previous=STARTING]
2025-10-09 00:30:30 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:7071: registering service...
2025-10-09 00:30:30 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:7071 - registration status: 204
2025-10-09 00:30:30 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customer-service-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customer-service-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-09 00:30:30 [main] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-10-09 00:30:30 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:30:30 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:30:30 [main] INFO  o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:30:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759987830757
2025-10-09 00:30:30 [main] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Subscribed to topic(s): customer-created
2025-10-09 00:30:30 [main] INFO  c.b.c.CustomerServiceApplication - Started CustomerServiceApplication in 7.918 seconds (process running for 8.46)
2025-10-09 00:30:30 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Cluster ID: fr9HVN4fSCq5BrFxSZ-pAQ
2025-10-09 00:30:30 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-10-09 00:30:30 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] (Re-)joining group
2025-10-09 00:30:30 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: need to re-join with the given member-id: consumer-customer-service-group-1-bdc81c31-a432-4cc2-9218-57c0c9e2b68a
2025-10-09 00:30:30 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] (Re-)joining group
2025-10-09 00:30:33 [parallel-1] DEBUG c.b.c.i.e.ClienteNaturalController - POST /cliente/natural
2025-10-09 00:30:33 [reactor-http-nio-3] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Registrando cliente natural: ClienteNaturalCommand[id=null, usuario=DatosUsuario[documento=DocumentoIdentificacion[type=DNI, numero=00000004], telefono=Telefono[numero=+51999999999, imei=7456745674567], correo=Correo[value=juan.perez@example.com]], tipo=NORMAL]
2025-10-09 00:30:33 [reactor-http-nio-3] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Obteniendo cliente natural por Docuemtno: DNI 00000004
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Successfully joined group with generation Generation{generationId=105, memberId='consumer-customer-service-group-1-bdc81c31-a432-4cc2-9218-57c0c9e2b68a', protocol='range'}
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Finished assignment for group at generation 105: {consumer-customer-service-group-1-bdc81c31-a432-4cc2-9218-57c0c9e2b68a=Assignment(partitions=[customer-created-0])}
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Successfully synced group in generation Generation{generationId=105, memberId='consumer-customer-service-group-1-bdc81c31-a432-4cc2-9218-57c0c9e2b68a', protocol='range'}
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Notifying assignor about the new Assignment(partitions=[customer-created-0])
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Adding newly assigned partitions: customer-created-0
2025-10-09 00:30:33 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition customer-created-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}
2025-10-09 00:30:35 [nioEventLoopGroup-3-7] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural registrado exitosamente: 52be4f65-d9b3-450c-8ca7-77205de41d9c
2025-10-09 00:30:43 [parallel-2] DEBUG c.b.c.i.e.ClienteNaturalController - PUT /cliente/natural/52be4f65-d9b3-450c-8ca7-77205de41d9c
2025-10-09 00:30:43 [reactor-http-nio-3] DEBUG c.b.c.a.s.ClienteNaturalServiceImpl - Actualizando cliente natural con ID: 52be4f65-d9b3-450c-8ca7-77205de41d9c
2025-10-09 00:30:44 [nioEventLoopGroup-3-7] INFO  c.b.c.a.s.ClienteNaturalServiceImpl - Cliente natural actualizado exitosamente: 52be4f65-d9b3-450c-8ca7-77205de41d9c
2025-10-09 00:32:00 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1759987920844, current=DOWN, previous=UP]
2025-10-09 00:32:00 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:7071: registering service...
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Revoke previously assigned partitions customer-created-0
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Member consumer-customer-service-group-1-bdc81c31-a432-4cc2-9218-57c0c9e2b68a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-09 00:32:00 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:7071 - registration status: 204
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:32:00 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customer-service-group-1 unregistered
2025-10-09 00:32:05 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
2025-10-09 00:32:08 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
2025-10-09 00:32:08 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_CUSTOMER-SERVICE/DESKTOP-UNU1A7E.mshome.net:customer-service:7071 - deregister  status: 200
2025-10-09 00:32:08 [SpringApplicationShutdownHook] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
2025-10-09 00:44:59 [background-preinit] INFO  o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.3.Final
2025-10-09 00:44:59 [main] INFO  c.b.c.CustomerServiceApplicationTests - Starting CustomerServiceApplicationTests using Java 21.0.8 with PID 10792 (started by Gonzalo in D:\NTT DATA\customer-service)
2025-10-09 00:44:59 [main] DEBUG c.b.c.CustomerServiceApplicationTests - Running with Spring Boot v3.4.10, Spring v6.2.11
2025-10-09 00:44:59 [main] INFO  c.b.c.CustomerServiceApplicationTests - No active profile set, falling back to 1 default profile: "default"
2025-10-09 00:45:02 [main] INFO  org.mongodb.driver.client - MongoClient with metadata {"application": {"name": "Cluster0"}, "driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "5.2.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/21.0.8+9-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='xaleons72_db_user', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@572b031f, socketChannelClass=null, allocator=null, sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@23685592], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@495590a7, com.mongodb.Jep395RecordCodecProvider@9b195c4, com.mongodb.KotlinCodecProvider@60d5c16]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=cluster0.bst1l3t.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-mp34t7-shard-0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@67a84d80], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='Cluster0', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
2025-10-09 00:45:03 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:45:03 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:45:03 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-srv-cluster0.bst1l3t.mongodb.net] INFO  org.mongodb.driver.cluster - Adding discovered server ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017 to client view of cluster
2025-10-09 00:45:05 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=652567800, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e520a3031463f16b1ec4de, counter=6}, lastWriteDate=Thu Oct 09 00:45:05 COT 2025, lastUpdateTimeNanos=390324538318300}
2025-10-09 00:45:05 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, type=REPLICA_SET_PRIMARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=652566300, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000025a, setVersion=324, topologyVersion=TopologyVersion{processId=68e54c58ed1645ec4e11f896, counter=7}, lastWriteDate=Thu Oct 09 00:45:05 COT 2025, lastUpdateTimeNanos=390324538318400}
2025-10-09 00:45:05 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, type=REPLICA_SET_SECONDARY, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=652544500, minRoundTripTimeNanos=0, setName='atlas-mp34t7-shard-0', canonicalAddress=ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017, hosts=[ac-twu7l2c-shard-00-00.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017, ac-twu7l2c-shard-00-01.bst1l3t.mongodb.net:27017], passives=[], arbiters=[], primary='ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017', tagSet=TagSet{[Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AZURE'}, Tag{name='region', value='US_EAST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=324, topologyVersion=TopologyVersion{processId=68e5710e940ac22a86255593, counter=4}, lastWriteDate=Thu Oct 09 00:45:05 COT 2025, lastUpdateTimeNanos=390324538318200}
2025-10-09 00:45:05 [cluster-ClusterId{value='68e74bde7d060b044f30e3ad', description='Cluster0'}-ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017] INFO  org.mongodb.driver.cluster - Discovered replica set primary ac-twu7l2c-shard-00-02.bst1l3t.mongodb.net:27017 with max election id 7fffffff000000000000025a and max set version 324
2025-10-09 00:45:05 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = customer-service-admin-0
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-09 00:45:06 [main] INFO  o.a.k.c.admin.AdminClientConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759988706128
2025-10-09 00:45:06 [kafka-admin-client-thread | customer-service-admin-0] WARN  o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=customer-service-admin-0] The DescribeTopicPartitions API is not supported, using Metadata API to describe topics.
2025-10-09 00:45:06 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for customer-service-admin-0 unregistered
2025-10-09 00:45:06 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:45:06 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:45:06 [kafka-admin-client-thread | customer-service-admin-0] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:45:06 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customer-service-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customer-service-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-09 00:45:06 [main] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-10-09 00:45:06 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:45:06 [main] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-09 00:45:06 [main] INFO  o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.8.1
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 70d6ff42debf7e17
2025-10-09 00:45:06 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1759988706862
2025-10-09 00:45:06 [main] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Subscribed to topic(s): customer-created
2025-10-09 00:45:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Cluster ID: fr9HVN4fSCq5BrFxSZ-pAQ
2025-10-09 00:45:06 [main] INFO  c.b.c.CustomerServiceApplicationTests - Started CustomerServiceApplicationTests in 10.158 seconds (process running for 12.065)
2025-10-09 00:45:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-10-09 00:45:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] (Re-)joining group
2025-10-09 00:45:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: need to re-join with the given member-id: consumer-customer-service-group-1-d842854b-dc76-47a3-82fd-d7898984626c
2025-10-09 00:45:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] (Re-)joining group
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Member consumer-customer-service-group-1-d842854b-dc76-47a3-82fd-d7898984626c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-09 00:45:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customer-service-group-1, groupId=customer-service-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-09 00:45:09 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-10-09 00:45:09 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-09 00:45:09 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-09 00:45:09 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-10-09 00:45:09 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customer-service-group-1 unregistered
